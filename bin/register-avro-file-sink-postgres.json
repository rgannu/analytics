{
  "name": "analytics-avro-file-sink-connector",
  "config": {
    "_comment": "Stream data to file from Kafka topic using CamelLogSinkConnector",
    "connector.class": "org.apache.camel.kafkaconnector.file.CamelFileSinkConnector",

    "tasks.max": "1",

    "_comment": "--- File specific configuration here ---",
    "_comment": "If true, mask sensitive information like password or passphrase in the log",
    "camel.sink.contentLogLevel": "DEBUG",

    "camel.sink.endpoint.level": "TRACE",
    "camel.sink.endpoint.showFiles": "true",
    "camel.sink.endpoint.showCaughtException": "true",
    "camel.sink.endpoint.showException": "true",
    "camel.sink.endpoint.showStackTrace": "true",
    "camel.sink.url": "file:/tmp/?fileName=kafkaconnect-avro.txt&fileExist=Append",

    "transforms":"unwrap,outbox",
    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
    "transforms.unwrap.drop.tombstones": "false",
    "transforms.unwrap.delete.handling.mode": "rewrite",
    "transforms.unwrap.add.fields": "op,table,lsn,source.ts_ms",
    "transforms.outbox.type": "org.apache.camel.kafkaconnector.transforms.CamelTypeConverterTransform$Value",
    "transforms.outbox.target.type": "java.lang.String",

    "_comment": "Which topic(s) to write data from",
    "topics.regex": "^dbanalytics.services.(.*)",

    "key.converter": "io.confluent.connect.avro.AvroConverter",
    "value.converter": "io.confluent.connect.avro.AvroConverter",
    "key.converter.schema.registry.url": "http://schema-registry:18081",
    "value.converter.schema.registry.url": "http://schema-registry:18081",
    "key.converter.schemas.enable": "true",
    "value.converter.schemas.enable": "true"
  }
}
