version: "3.7"
services:
  rabbitmq:
    container_name: rabbitmq
    build:
      context: ./docker/rabbitmq
      dockerfile: Dockerfile
    ports:
      - "5672:5672"
      - "15672:15672"

  zookeeper:
    hostname: zookeeper
    image: debezium/zookeeper:${DEBEZIUM_ZK_VERSION}
    ports:
      - 2181:2181
      - 2888:2888
      - 3888:3888

  kafka:
    image: debezium/kafka:${DEBEZIUM_KAFKA_VERSION}
    ports:
      - 9092:9092
    links:
      - zookeeper
    environment:
      - ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_MESSAGE_MAX_BYTES=5242880
      - KAFKA_REPLICA_FETCH_MAX_BYTES=5242880
      - KAFKA_MAX_REQUEST_SIZE=5242880
      - KAFKA_FETCH_MESSAGE_MAX_BYTES=5242880

  db:
    build:
      context: ./docker/postgres
      dockerfile: Dockerfile
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

  flyway:
    depends_on:
      - db
    image: flyway/flyway
    command: -url=jdbc:postgresql://db/services repair migrate
    volumes:
      - ./docker/flyway/conf:/flyway/conf
      - ./docker/flyway/migration:/flyway/sql/migration
      - ./docker/flyway/migration-analytics:/flyway/sql/migration-analytics

  schema-registry:
    image: confluentinc/cp-schema-registry
    ports:
      - 18181:8181
      - 18081:8081
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:18081
    links:
      - zookeeper

  connect:
    build:
      context: ./docker/connect
      dockerfile: Dockerfile
      args:
        customerEnv: dev
    ports:
      - 18083:8083
    volumes:
      - ./docker/connect:/connect-volume
    links:
      - kafka
      - db
      - schema-registry
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=my_connect_configs
      - OFFSET_STORAGE_TOPIC=my_connect_offsets
      - STATUS_STORAGE_TOPIC=my_connect_statuses
      - KAFKA_PRODUCER_MAX_REQUEST_SIZE=6000000
      - CONNECT_PRODUCER_MAX_REQUEST_SIZE=6000000
      - CONNECT_CONSUMER_MAX_REQUEST_SIZE=6000000
      - CONNECT_CONFIG_PROVIDERS=file
      - CONNECT_CONFIG_PROVIDERS_FILE_CLASS=org.apache.kafka.common.config.provider.FileConfigProvider
      - AMQP_HOSTNAME=rabbitmq
      - AMQP_PORT=5672
      - AMQP_USERNAME=guest
      - AMQP_PASSWORD=guest
      - AMQP_EXCHANGE=analytics-exchange
      - AMQP_EXCHANGE_TYPE=topic
      - AMQP_ANALYTICS_ROUTING_KEY=analytics
      - AMQP_SCHEMA_ROUTING_KEY=analytics-schema

  ksql-server:
    image: confluentinc/cp-ksql-server:5.0.1
    hostname: ksql-server
    container_name: ksql-server
    depends_on:
      - kafka
      - connect
    ports:
      - "18088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://connect:18083
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:18081

  ksql-cli:
    image: confluentinc/cp-ksql-cli:5.0.1
    container_name: ksql-cli
    hostname: ksql-cli
    depends_on:
      - ksql-server
    entrypoint: /bin/sh
    tty: true

networks:
  default:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.1/16
